{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HyeonhoonLee/SNUCM_Medical_DataScience_2025_Fall/blob/main/04_Chapter_4_Examples_and_Few_Shot_Prompting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbXQfErCoVvg"
      },
      "source": [
        "# **Chapter 4. Examples and Few-Shot Prompting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7P1xArgOoVvk"
      },
      "source": [
        "There are a number of well-known prompting techniques that use examples, such as zero-shot, one-shot, and few-shot prompting. By understanding each approach and the principles of designing effective examples, you can significantly enhance the performance of Solar.\n",
        "\n",
        "This chapter is based on Prompt `Type C`:  Instruction + Context + **Example** + Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkX6Wv3DoVvl"
      },
      "source": [
        "## **Table of Contents**\n",
        "- Use `Ctrl + F` (Windows) or `Cmd + F` (Mac) to locate specific sections by title."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rn1ioVpQoVvm"
      },
      "source": [
        "- **4.1 Zero-Shot Prompting**\n",
        "\n",
        "    - 4.1.1 Introduction\n",
        "\n",
        "    - 4.1.2 Example\n",
        "\n",
        "    - 4.1.3 Practice\n",
        "\n",
        "\n",
        "- **4.2 One-Shot Prompting**\n",
        "\n",
        "    - 4.2.1 Introduction\n",
        "\n",
        "    - 4.2.2 Example\n",
        "\n",
        "    - 4.2.3 Practice\n",
        "\n",
        "\n",
        "- **4.3 Few-Shot Prompting**\n",
        "\n",
        "    - 4.3.1 Introduction\n",
        "\n",
        "    - 4.3.2 Examples\n",
        "\n",
        "        - (1) Exemplar Quantity\n",
        "\n",
        "        - (2) Exemplar Similarity\n",
        "\n",
        "        - (3) Exemplar Format"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34QMMkIpoVvn"
      },
      "source": [
        "**Set up**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HG8v1fGoVvo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d15899a8-ff6a-4529-bf38-2b16c7fd8bff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "no stored variable or alias UPSTAGE_API_KEY\n",
            "Since, name 'UPSTAGE_API_KEY' is not defined\n",
            "up_l58DKoZNMHKJ97k4m9fqdpHnwZU7v\n",
            "UPSTAGE_API_KEY =up_l58DKoZNMHKJ97k4m9fqdpHnwZU7v\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "# Retrieve the UPSTAGE_API_KEY variable from the IPython store\n",
        "%store -r UPSTAGE_API_KEY\n",
        "\n",
        "try:\n",
        "    if UPSTAGE_API_KEY:\n",
        "        print(\"Success!\")\n",
        "except NameError as ne:\n",
        "    print(f\"Since, {ne}\")\n",
        "    print(\"up_l58DKoZNMHKJ97k4m9fqdpHnwZU7v\")\n",
        "    UPSTAGE_API_KEY = input(\"UPSTAGE_API_KEY =up_l58DKoZNMHKJ97k4m9fqdpHnwZU7v\")\n",
        "\n",
        "# Set your API key:\n",
        "# UPSTAGE_API_KEY = \" \" ←- Insert your API key here.\n",
        "\n",
        "client = OpenAI(\n",
        "    api_key= UPSTAGE_API_KEY,\n",
        "    base_url=\"https://api.upstage.ai/v1/solar\"\n",
        ")\n",
        "\n",
        "config_model = {\n",
        "    \"model\": \"solar-pro2\",\n",
        "    \"max_tokens\": 2000,\n",
        "    \"temperature\": 0.7,\n",
        "    \"top_p\": 0.9,\n",
        "}\n",
        "\n",
        "def get_completion(messages, system_prompt=\"\", config=config_model):\n",
        "    try:\n",
        "        if system_prompt:\n",
        "            messages = [{\"role\": \"system\", \"content\": system_prompt}] + messages\n",
        "\n",
        "        message = client.chat.completions.create(messages=messages, **config)\n",
        "        return message.choices[0].message.content\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during API call: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wreH7_koVvr"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2nbG148oVvu"
      },
      "source": [
        "## **4.1 Zero-Shot Prompting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-dUzIwkoVvv"
      },
      "source": [
        "### **4.1.1 Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGhNbEKCoVvw"
      },
      "source": [
        "**Zero-shot prompting** is a technique where the model is asked to perform a task without any prior examples. There are numerous ways to craft zero-shot prompts. This is one of the powerful features of language models—it allows them to perform various tasks with minimal information."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54lUDVWZoVvw"
      },
      "source": [
        "### **4.1.2 Example**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8qxdCPHoVvw",
        "outputId": "25f8db55-9861-4b92-a96c-9ed3aebc6068"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentiment: Neutral \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Prompt:\n",
        "message = [\n",
        "    {\n",
        "        \"role\":\"user\",\n",
        "        \"content\": \"Classify the following text as positive, negative, or neutral. Text: I thought the macaron flavor was just okay. Sentiment: { }\"\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(messages=message)\n",
        "print(response, \"\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LK0oaM49oVvx"
      },
      "source": [
        "### **4.1.3 Practice**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Stu2WOA6oVvx"
      },
      "source": [
        "→ Translate the term 'artificial tears' from English into Japanese."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YNV1-KdloVvy"
      },
      "outputs": [],
      "source": [
        "# Prompt:\n",
        "message = [\n",
        "    {\n",
        "        \"role\":\"user\",\n",
        "        \"content\": \" \" # ←- Insert your prompt here.\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(messages=message)\n",
        "print(response, \"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOz9OkMboVvz"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHH9MOVvoVvz"
      },
      "source": [
        "## **4.2 One-Shot Prompting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11FzGhHboVvz"
      },
      "source": [
        "### **4.2.1 Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxQ4LSSAoVv0"
      },
      "source": [
        "**One-shot prompting** is a technique where the model is provided with only one example before it’s asked to complete the task."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHeqF9sdoVv0"
      },
      "source": [
        "### **4.2.2 Example**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PDHEwTEoVv0",
        "outputId": "9e8cd262-4c3d-4b33-93a8-97d6693a5b1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "J'adore étudier les langues. \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Prompt:\n",
        "message = [\n",
        "    {\n",
        "        \"role\":\"user\",\n",
        "        \"content\": \"Translate the following sentence into French: I like reading books.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\":\"assistant\",\n",
        "        \"content\": \"J'aime lire des livres.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\":\"user\",\n",
        "        \"content\": \"Translate the following sentence into French: I love studying language\"\n",
        "    },\n",
        "]\n",
        "\n",
        "response = get_completion(messages=message)\n",
        "print(response, \"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goT29nOQoVv1"
      },
      "source": [
        "### **4.2.3 Practice**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2ROr5K2oVv1"
      },
      "source": [
        "→ Translate the term 'artificial tears' from English to Japanese using one-shot prompting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUYtnuWUoVv1"
      },
      "outputs": [],
      "source": [
        "# Prompt:\n",
        "message = [\n",
        "    {\" \"} # ←- Insert your prompt here.\n",
        "]\n",
        "\n",
        "response = get_completion(messages=message)\n",
        "print(response, \"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-f4d9UV0oVv1"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IKZfmwBpoVv2"
      },
      "source": [
        "## **4.3 Few-Shot Prompting**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dKh2uPdyoVv2"
      },
      "source": [
        "### **4.3.1 Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc41m7XFoVv2"
      },
      "source": [
        "**Few-shot prompting** is a technique where the model is given a handful of examples—typically two to five—before it is asked to complete the task. This approach offers the model multiple references for the type of output desired, providing more context and making the output more accurate or aligned with specific patterns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miG0xc9toVv2"
      },
      "source": [
        "> It's important to note that **few-shot learning** and **few-shot prompting** are distinct concepts. Few-shot learning is a broader machine learning approach focused on adapting model parameters with only a few examples. In contrast, **few-shot prompting** specifically applies to prompt design in generative AI, where model parameters remain unchanged."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q3uvAyboVv2"
      },
      "source": [
        "### **4.3.2 Examples**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqCxa_FtoVv3",
        "outputId": "6ae70e72-e96a-48e8-af93-10443d69e407"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " four hundred and one \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Prompt:\n",
        "message = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"2+10:\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"twelve\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"4+52:\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"fifty-six\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"100+301:\"\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(messages=message)\n",
        "print(response, \"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzBYYGMZoVv3"
      },
      "source": [
        "We would like to highlight **three ways** to design effective examples when using Solar:\n",
        "\n",
        "- **Exemplar Quantity**\n",
        "- **Exemplar Similarity**\n",
        "- **Exemplar Format**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLyAMPtroVv3"
      },
      "source": [
        "#### **(1) Exemplar Quantity**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpjQKh-HoVv4"
      },
      "source": [
        ":Mostly, the quantity of exemplars in the prompt generally improves model\n",
        "performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uz3uo0wloVv4",
        "outputId": "00a19181-e0f6-4a3b-975e-572b0ea82637"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence: \"Thick smog chokes northern India and eastern Pakistan ahead of Diwali.\"\n",
            "Subject: \"Thick smog\"\n",
            "Verb: \"chokes\"\n",
            "Direct Object: \"northern India and eastern Pakistan\"\n",
            "Prepositional Phrase: \"ahead of Diwali\"\n",
            "Analysis: Subject-verb-direct object structure with a prepositional phrase providing additional context. \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Prompt:\n",
        "message = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"The cat sleeps.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"\"\"Sentence: \"The cat sleeps.\"\n",
        "Subject: \"The cat\"\n",
        "Verb: \"sleeps\"\n",
        "Object: None\n",
        "Analysis: Simple subject-verb sentence structure with a single actor performing an action.\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"She reads books.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"\"\"Sentence: \"She reads books.\"\n",
        "Subject: \"She\"\n",
        "Verb: \"reads\"\n",
        "Object: \"books\"\n",
        "Analysis: Subject-verb-object structure, indicating the action is directed toward an object.\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"They dance gracefully.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"\"\"Sentence: \"They dance gracefully.\"\n",
        "Subject: \"They\"\n",
        "Verb: \"dance\"\n",
        "Adverb: \"gracefully\"\n",
        "Analysis: Subject-verb-adverb structure, with the adverb modifying how the action is performed.\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"The sun rises in the east.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": \"\"\"Sentence: \"The sun rises in the east.\"\n",
        "Subject: \"The sun\"\n",
        "Verb: \"rises\"\n",
        "Prepositional Phrase: \"in the east\"\n",
        "Analysis: Subject-verb-prepositional phrase structure, adding context about the action's location.\"\"\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Thick smog chokes northern India and eastern Pakistan ahead of Diwali.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(messages=message)\n",
        "print(response, \"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ispsfoq-oVv4",
        "outputId": "e2a89121-12df-4fb9-ea4a-54cb7121aa87"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In the sentence \"Thick smog chokes northern India and eastern Pakistan ahead of Diwali,\" the components are as follows:\n",
            "\n",
            "1. Thick smog: Subject (noun phrase), referring to the polluted air.\n",
            "2. chokes: Verb, indicating the action of causing difficulty in breathing.\n",
            "3. northern India and eastern Pakistan: Direct object (noun phrase), referring to the locations affected by the smog.\n",
            "4. ahead of Diwali: Prepositional phrase, providing context and indicating the time of the event.\n",
            "\n",
            "The sentence describes a situation where the polluted air, or smog, is causing difficulty in breathing in northern India and eastern Pakistan, and this situation occurs before the Diwali festival. \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# without an example\n",
        "\n",
        "# Prompt:\n",
        "message = [\n",
        "    {\n",
        "        \"role\":\"user\",\n",
        "        \"content\": \"\"\"Please analyze and define the sentence components in the following sentence.\n",
        "        sentence: \"Thick smog chokes northern India and eastern Pakistan ahead of Diwali.\"\n",
        "        \"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(messages=message)\n",
        "print(response, \"\\n\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z4nUc3yoVv8"
      },
      "source": [
        "> Observation: If you provide an example, you can see the model respond in the format used in the example. Even with complex and varied sentence structures, using many examples to guide the model helps it perform the task well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbvzAub9oVv9"
      },
      "source": [
        "#### **(2) Exemplar Similarity**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXfARy6qoVv9"
      },
      "source": [
        "Select exemplars that are similar to your task. For example, if you are summarizing a news article, using exemplars in the same format will yield the best results you desire."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT-WbKvEoVwG"
      },
      "source": [
        "In the following prompt example, you can see that the summary results use **a consistent response format** as an example. By increasing the consistency of the format, you can achieve more accurate results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OBASah9aoVwH",
        "outputId": "fc0073bd-a1fe-4d01-dff2-ff1c355ada47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#OSAID / Defines open source AI as a model that allows full understanding of its construction and provides usage rights like the freedom to use, modify, and build on top./\n",
            "#Maffulli / Criticizes Meta's use of \"open source\" label and expects the AI community to correct misuse of the term./\n",
            "#AI Study / Finds that many \"open source\" models are not truly open source, as they keep training data secret, require significant compute power, and use complex fine-tuning techniques./ \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# When examples have the similarities\n",
        "# Prompt:\n",
        "message = [\n",
        "    {\n",
        "        \"role\":\"user\",\n",
        "        \"content\": \"\"\"Read the following text and summarize the key points. Once you finish the summary, organize it as follows:\n",
        "\n",
        "#Keyword 1 / Related key point in one short phrase./\n",
        "#Keyword 2 / Related key point in one short phrase./\n",
        "#Keyword 3 / Related key point in one short phrase./\n",
        "\n",
        "<text>\n",
        "To be considered open source under the OSAID, an AI model has to provide enough information about its design so that a person could “substantially” recreate it. The model must also disclose any pertinent details about its training data, including the provenance, how the data was processed, and how it can be obtained or licensed.\n",
        "“An open source AI is an AI model that allows you to fully understand how it’s been built,” Maffulli said. “That means that you have access to all the components, such as the complete code used for training and data filtering.”\n",
        "The OSAID also lays out usage rights developers should expect with open source AI, like the freedom to use the model for any purpose and modify it without having to ask anyone’s permission. “Most importantly, you should be able to build on top,” added Maffulli.\n",
        "The OSI has no enforcement mechanisms to speak of. It can’t pressure developers to abide by or follow the OSAID. But it does intend to flag models described as “open source” but which fall short of the definition.\n",
        "“Our hope is that when someone tries to abuse the term, the AI community will say, ‘We don’t recognize this as open source,’ and it gets corrected,” Maffulli said. Historically, this has had mixed results, but it isn’t entirely without effect.\n",
        "Many startups and big tech companies, most prominently Meta, have employed the term “open source” to describe their AI model release strategies — but few meet the OSAID’s criteria. For example, Meta mandates that platforms with over 700 million monthly active users request a special license to use its [Llama](https://techcrunch.com/2024/09/08/meta-llama-everything-you-need-to-know-about-the-open-generative-ai-model/) models.\n",
        "Maffulli has been [openly critical](https://www.ft.com/content/397c50d8-8796-4042-a814-0ac2c068361f) of Meta’s decision to call its models “open source.” After discussions with the OSI, Google and Microsoft agreed to drop their use of the term for models that aren’t fully open, but Meta hasn’t, he said.\n",
        "Stability AI, which has long advertised its models as “open,” requires that businesses making more than $1 million in revenue obtain an enterprise license. And French AI upstart Mistral’s license bars the use of certain models and outputs for commercial ventures.\n",
        "A [study](https://www.wired.com/story/the-myth-of-open-source-ai/) last August by researchers at the Signal Foundation, the nonprofit AI Now Institute, and Carnegie Mellon found that many “open source” models are basically open source in name only. The data required to train the models is kept secret, the compute power needed to run them is beyond the reach of many developers, and the techniques to fine-tune them are intimidatingly complex.\n",
        "Instead of democratizing AI, these “open source” projects tend to entrench and expand centralized power, the study’s authors concluded. Indeed, Meta’s Lllama models have [racked up](https://venturebeat.com/ai/meta-leads-open-source-ai-boom-llama-downloads-surge-10x-year-over-year/) hundreds of millions of downloads, and Stability [claims](https://www.prnewswire.com/news-releases/stability-ai-secures-significant-new-investment-from-world-class-investor-group-and-appoints-prem-akkaraju-as-ceo-302181923.html) that its models power up to 80% of all AI-generated imagery.\n",
        "</text>\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(messages=message)\n",
        "print(response, \"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVpSHSM9oVwI"
      },
      "outputs": [],
      "source": [
        "# When examples don't have the similarities\n",
        "# Prompt:\n",
        "message = [\n",
        "    {\n",
        "        \"role\":\"user\",\n",
        "        \"content\": \"\"\"Read the following text and summarize the key points. Once you finish the summary, organize it as follows:\n",
        "\n",
        "Related key point in one short phrase./Keyword 1\n",
        "Keyword 2 Related key point in two short phrases.\n",
        "Keyword 3/ Related key point in three short phrases.\n",
        "\n",
        "<text>\n",
        "To be considered open source under the OSAID, an AI model has to provide enough information about its design so that a person could “substantially” recreate it. The model must also disclose any pertinent details about its training data, including the provenance, how the data was processed, and how it can be obtained or licensed.\n",
        "“An open source AI is an AI model that allows you to fully understand how it’s been built,” Maffulli said. “That means that you have access to all the components, such as the complete code used for training and data filtering.”\n",
        "The OSAID also lays out usage rights developers should expect with open source AI, like the freedom to use the model for any purpose and modify it without having to ask anyone’s permission. “Most importantly, you should be able to build on top,” added Maffulli.\n",
        "The OSI has no enforcement mechanisms to speak of. It can’t pressure developers to abide by or follow the OSAID. But it does intend to flag models described as “open source” but which fall short of the definition.\n",
        "“Our hope is that when someone tries to abuse the term, the AI community will say, ‘We don’t recognize this as open source,’ and it gets corrected,” Maffulli said. Historically, this has had mixed results, but it isn’t entirely without effect.\n",
        "Many startups and big tech companies, most prominently Meta, have employed the term “open source” to describe their AI model release strategies — but few meet the OSAID’s criteria. For example, Meta mandates that platforms with over 700 million monthly active users request a special license to use its [Llama](https://techcrunch.com/2024/09/08/meta-llama-everything-you-need-to-know-about-the-open-generative-ai-model/) models.\n",
        "Maffulli has been [openly critical](https://www.ft.com/content/397c50d8-8796-4042-a814-0ac2c068361f) of Meta’s decision to call its models “open source.” After discussions with the OSI, Google and Microsoft agreed to drop their use of the term for models that aren’t fully open, but Meta hasn’t, he said.\n",
        "Stability AI, which has long advertised its models as “open,” requires that businesses making more than $1 million in revenue obtain an enterprise license. And French AI upstart Mistral’s license bars the use of certain models and outputs for commercial ventures.\n",
        "A [study](https://www.wired.com/story/the-myth-of-open-source-ai/) last August by researchers at the Signal Foundation, the nonprofit AI Now Institute, and Carnegie Mellon found that many “open source” models are basically open source in name only. The data required to train the models is kept secret, the compute power needed to run them is beyond the reach of many developers, and the techniques to fine-tune them are intimidatingly complex.\n",
        "Instead of democratizing AI, these “open source” projects tend to entrench and expand centralized power, the study’s authors concluded. Indeed, Meta’s Lllama models have [racked up](https://venturebeat.com/ai/meta-leads-open-source-ai-boom-llama-downloads-surge-10x-year-over-year/) hundreds of millions of downloads, and Stability [claims](https://www.prnewswire.com/news-releases/stability-ai-secures-significant-new-investment-from-world-class-investor-group-and-appoints-prem-akkaraju-as-ceo-302181923.html) that its models power up to 80% of all AI-generated imagery.\n",
        "\n",
        "</text>\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "responses = []\n",
        "for i in range(3):\n",
        "    response = get_completion(messages=message)\n",
        "    responses.append(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShRrRHh0oVwJ"
      },
      "source": [
        "- As seen in the following results, prompts with lower similarity among examples yield a wider variety of outcomes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Hxx3XERoVwJ",
        "outputId": "95423960-47e8-4dc3-d15b-1a897ea9b63a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n = 1\n",
            "Open source AI criteria/Keyword 1\n",
            "Keyword 2 Disclosure of AI model design and training data/Keyword 3\n",
            "Keyword 4 Freedom to use, modify, and build upon open source AI models/Keyword 5\n",
            "\n",
            "\n",
            "n = 2\n",
            "Open source AI model definition/OSAID\n",
            "Maffulli explains Open source AI as a model with full understanding of its build, including access to all components, such as complete code for training and data filtering.\n",
            "OSI's role/OSI enforcement\n",
            "The OSI aims to flag models described as \"open source\" but falling short of the definition, with no enforcement mechanisms, relying on the AI community to correct misuse.\n",
            "Study on \"open source\" AI models/Study findings\n",
            "A study found that many \"open source\" models are open source in name only, with secret training data, inaccessible compute power, and complex fine-tuning techniques, entrenching centralized power.\n",
            "\n",
            "\n",
            "n = 3\n",
            "Open source AI definition/OSAID requires access to complete code, training data, and usage rights.\n",
            "OSI enforcement/OSI has no enforcement mechanisms but can flag models that don't meet the definition.\n",
            "AI community's response/AI community may reject misuse of term, but results are mixed.\n",
            "\n",
            "Many companies use \"open source\" label inaccurately/Few companies meet OSAID criteria, like Meta's special license requirement for large platforms.\n",
            "Stability AI and Mistral impose licensing restrictions/These companies require enterprise licenses or restrict commercial use.\n",
            "Study reveals limitations of \"open source\" AI/Many \"open source\" models are complex, require significant compute power, and have hidden data.\n",
            "Open source AI projects entrench centralized power/These projects often benefit large companies, like Meta and Stability AI.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(3):\n",
        "    print(f\"n = {i+1}\")\n",
        "    print(responses[i])\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cHy0HrVoVwJ"
      },
      "source": [
        "#### **(3) Exemplar Format**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PN2jsY6oVwJ"
      },
      "source": [
        "Use a common template. The optimal format may vary across tasks.\n",
        "\n",
        "There is evidence indicating that formats frequently found in the training data tend to result in improved performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgzWU2pDoVwJ",
        "outputId": "dca75c6b-003b-4116-f50c-101516bb6069"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "- company names: \n",
            "- personal names: \n",
            "- specific topics: \n",
            "    - SOLAR 10.7B\n",
            "    - large language model (LLM)\n",
            "    - depth up-scaling (DUS)\n",
            "    - mixture-of-experts\n",
            "    - natural language processing (NLP)\n",
            "    - instruction-following capabilities\n",
            "- themes: \n",
            "    - language model development\n",
            "    - model scaling\n",
            "    - model efficiency\n",
            "    - model fine-tuning\n",
            "    - open-source licensing \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Prompt:\n",
        "message = [\n",
        "    {\n",
        "        \"role\":\"user\",\n",
        "        \"content\": \"\"\"Identify the entities referenced in the text below.\n",
        "\n",
        "Please extract the following four types of entities:\n",
        "- company names:\n",
        "- personal names:\n",
        "- specific topics:\n",
        "- themes:\n",
        "\n",
        "<text>\n",
        "We introduce SOLAR 10.7B, a large language model (LLM) with 10.7 billion parameters, demonstrating superior performance in various natural language processing (NLP) tasks. Inspired by recent efforts to efficiently up-scale LLMs, we present a method for scaling LLMs called depth up-scaling (DUS), which encompasses depthwise scaling and continued pretraining. In contrast to other LLM up-scaling methods that use mixture-of-experts, DUS does not require complex changes to train and inference efficiently. We show experimentally that DUS is simple yet effective in scaling up high-performance LLMs from small ones. Building on the DUS model, we additionally present SOLAR 10.7B-Instruct, a variant fine-tuned for instruction-following capabilities, surpassing Mixtral-8x7B-Instruct. SOLAR 10.7B is publicly available under the Apache 2.0 license, promoting broad access and application in the LLM field.\n",
        "</text>\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(messages=message)\n",
        "print(response, \"\\n\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCqvXrNPoVwK"
      },
      "outputs": [],
      "source": [
        "# When not using a standard format\n",
        "# Prompt:\n",
        "message = [\n",
        "    {\n",
        "        \"role\":\"user\",\n",
        "        \"content\": \"\"\"Identify the entities referenced in the text below.\n",
        "\n",
        "Please extract the following four types of entities:\n",
        "% % company names\n",
        "% % personal names\n",
        "% % specific topics% %\n",
        "% %  themes % %\n",
        "\n",
        "~text~\n",
        "We introduce SOLAR 10.7B, a large language model (LLM) with 10.7 billion parameters, demonstrating superior performance in various natural language processing (NLP) tasks. Inspired by recent efforts to efficiently up-scale LLMs, we present a method for scaling LLMs called depth up-scaling (DUS), which encompasses depthwise scaling and continued pretraining. In contrast to other LLM up-scaling methods that use mixture-of-experts, DUS does not require complex changes to train and inference efficiently. We show experimentally that DUS is simple yet effective in scaling up high-performance LLMs from small ones. Building on the DUS model, we additionally present SOLAR 10.7B-Instruct, a variant fine-tuned for instruction-following capabilities, surpassing Mixtral-8x7B-Instruct. SOLAR 10.7B is publicly available under the Apache 2.0 license, promoting broad access and application in the LLM field.\n",
        "~text~\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "responses = []\n",
        "for i in range(2):\n",
        "    response = get_completion(messages=message)\n",
        "    responses.append(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PE3y216doVwK"
      },
      "source": [
        "- When using unusual format symbols or marks, the stability of the results decreases each time they are generated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nBd3RFkPoVwK",
        "outputId": "9b36e78b-2859-4607-bf5e-07013b169bb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n = 1\n",
            "company names: SOLAR\n",
            "\n",
            "personal names:\n",
            "\n",
            "specific topics:\n",
            "\n",
            "themes: Large language models (LLMs), natural language processing (NLP), scaling LLMs, depth up-scaling (DUS), mixture-of-experts, instruction-following capabilities, Apache 2.0 license\n",
            "\n",
            "\n",
            "n = 2\n",
            "company names: SOLAR\n",
            "\n",
            "personal names:\n",
            "\n",
            "specific topics: language model (LLM), natural language processing (NLP), depth up-scaling (DUS), mixture-of-experts, instruction-following capabilities\n",
            "\n",
            "themes: Large language model performance, LLM scaling methods, LLM accessibility\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(2):\n",
        "    print(f\"n = {i+1}\")\n",
        "    print(responses[i])\n",
        "    print(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **4.3.3 Practice**"
      ],
      "metadata": {
        "id": "jpM-U-Zg0ZXE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Topic: Extracting Structured Entities from a Medical Abstract (based on the Covid-19 vaccine study)**"
      ],
      "metadata": {
        "id": "R2wW_-GZ0g8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://www.nejm.org/doi/full/10.1056/NEJMoa2510226?query=featured_home"
      ],
      "metadata": {
        "id": "rZN6a2qT4J-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# FEW-SHOT PROMPTING PRACTICE (MEDICAL ENTITY EXTRACTION)\n",
        "# 1) Quantity  2) Similarity  3) Format\n",
        "# ============================================\n",
        "\n",
        "ABSTRACT = \"\"\"\n",
        "Background\n",
        "Amid the declining clinical severity of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection and diminishing public uptake of annual coronavirus disease 2019 (Covid-19) vaccines, contemporary evidence on vaccine effectiveness against clinically relevant outcomes is needed.\n",
        "Methods\n",
        "We conducted an observational study that used the electronic health records of the Department of Veterans Affairs to evaluate the effectiveness of the 2024–2025 Covid-19 vaccine among veterans who received the Covid-19 and influenza vaccines on the same day (164,132 participants) and in an active-comparator group of veterans who received the influenza vaccine only (131,839 participants), between September 3 and December 31, 2024. Participants were followed for 180 days or until the occurrence of an outcome, whichever came first. We used inverse-probability–weighted models to estimate vaccine effectiveness (calculated as 1 minus the risk ratio) against Covid-19–associated emergency department visits, hospitalizations, and deaths at 6 months.\n",
        "Results\n",
        "At 6 months of follow-up, the estimated vaccine effectiveness was 29.3% (95% CI, 19.1 to 39.2) against Covid-19–associated emergency department visits, 39.2% (95% CI, 21.6 to 54.5) against Covid-19–associated hospitalizations, and 64.0% (95% CI, 23.0 to 85.8) against Covid-19–associated deaths. Vaccine effectiveness against a composite of these outcomes was 28.3% (95% CI, 18.2 to 38.2). The Covid-19 vaccine was associated with decreased risks of these outcomes across prespecified subgroups.\n",
        "Conclusions\n",
        "In this national cohort of U.S. veterans, the receipt of the 2024–2025 Covid-19 vaccine was associated with decreased risks of severe clinical outcomes.\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "_nsmHdLA0gJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **(1) Exemplar Quantity**"
      ],
      "metadata": {
        "id": "sRXVP6ST2zsg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================\n",
        "# (1) Exemplar Quantity — Rich exemplars that imply \"5 keywords\"\n",
        "#     → We never say \"five\", but each exemplar outputs exactly 5 items.\n",
        "# =========================================================\n",
        "\n",
        "# --------- Few-shot with multiple exemplars (better) ---------\n",
        "message_few = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a medical NLP assistant. Extract core keywords from medical texts using concise medical terms.\"\n",
        "    },\n",
        "\n",
        "    # Exemplar 1 (rich info → assistant returns exactly 5 keywords)\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": (\n",
        "            \"Extract the core keywords from the following text:\\n\\n\"\n",
        "            \"Adults with type 2 diabetes were followed for 12 months to compare metformin versus lifestyle counseling. \"\n",
        "            \"Primary outcomes included change in A1c and fasting glucose; secondary outcomes included ER visit rate.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": (\n",
        "            \"Keywords:\\n\"\n",
        "            \"- type 2 diabetes\\n\"\n",
        "            \"- metformin\\n\"\n",
        "            \"- lifestyle counseling\\n\"\n",
        "            \"- A1c reduction\\n\"\n",
        "            \"- fasting glucose\"\n",
        "        )\n",
        "    },\n",
        "\n",
        "    # Exemplar 2\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": (\n",
        "            \"Extract the core keywords from the following text:\\n\\n\"\n",
        "            \"A national cohort of adults ≥65 received seasonal influenza vaccination. Over 6 months, vaccination was \"\n",
        "            \"associated with lower hospitalization, reduced mortality, and fewer ER visits compared with no vaccination.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": (\n",
        "            \"Keywords:\\n\"\n",
        "            \"- older adults (≥65)\\n\"\n",
        "            \"- influenza vaccine\\n\"\n",
        "            \"- hospitalization reduction\\n\"\n",
        "            \"- mortality reduction\\n\"\n",
        "            \"- ER visits\"\n",
        "        )\n",
        "    },\n",
        "\n",
        "    # Exemplar 3\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": (\n",
        "            \"Extract the core keywords from the following text:\\n\\n\"\n",
        "            \"Patients with essential hypertension were randomized to ACE inhibitor versus placebo for 24 weeks. \"\n",
        "            \"The ACE inhibitor lowered systolic and diastolic blood pressure and modestly reduced heart rate.\"\n",
        "        )\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": (\n",
        "            \"Keywords:\\n\"\n",
        "            \"- essential hypertension\\n\"\n",
        "            \"- ACE inhibitor\\n\"\n",
        "            \"- placebo\\n\"\n",
        "            \"- systolic/diastolic BP reduction\\n\"\n",
        "            \"- heart rate\"\n",
        "        )\n",
        "    },\n",
        "\n",
        "    # Target: your ABSTRACT (Covid-19 vaccine study) → the pattern nudges the model to return 5 keywords\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"Extract the core keywords from the following abstract:\\n\\n{ABSTRACT}\"\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(messages=message_few)\n",
        "print('FEW-SHOT (implied 5 keywords):\\n', response, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PIIRAs-S3WgL",
        "outputId": "f0564ea1-e33e-4a3e-b381-3c58b5092156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FEW-SHOT (implied 5 keywords):\n",
            " **Core Keywords:**  \n",
            "- SARS-CoV-2 infection  \n",
            "- Covid-19 vaccine (2024–2025)  \n",
            "- Influenza vaccine (active comparator)  \n",
            "- Vaccine effectiveness (VE)  \n",
            "- Emergency department (ED) visits  \n",
            "- Hospitalizations  \n",
            "- Mortality reduction  \n",
            "- Observational cohort study  \n",
            "- Veterans Affairs (VA) electronic health records  \n",
            "- Inverse-probability weighting  \n",
            "- Risk ratio (RR)  \n",
            "- Clinical outcomes (composite endpoint)  \n",
            "- Subgroup analysis  \n",
            "\n",
            "**Abbreviations/Terms:**  \n",
            "- ACE: Acute Coronary Syndrome (not applicable here; ensure context-specific terms)  \n",
            "- CI: Confidence interval  \n",
            "- SARS-CoV-2: Severe Acute Respiratory Syndrome Coronavirus 2  \n",
            "\n",
            "*(Note: Terms like \"essential hypertension\" or \"ACE inhibitor\" from prior examples are irrelevant here and excluded.)* \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------- Zero-shot (no exemplars; typically less consistent in #items) ---------\n",
        "message_zero = [\n",
        "    {\n",
        "        \"role\": \"system\",\n",
        "        \"content\": \"You are a medical NLP assistant. Extract core keywords from medical texts using concise medical terms.\"\n",
        "    },\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"Extract the core keywords from the following abstract:\\n\\n{ABSTRACT}\"\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(messages=message_zero)\n",
        "print('ZERO-SHOT (number of keywords may vary):\\n', response, '\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAW4ziiQ3nPl",
        "outputId": "6706d180-c271-42b8-a9c5-c3d80b015194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ZERO-SHOT (number of keywords may vary):\n",
            " **Core Keywords:**  \n",
            "1. **SARS-CoV-2**  \n",
            "2. **COVID-19 Vaccine** (2024–2025)  \n",
            "3. **Vaccine Effectiveness**  \n",
            "4. **Emergency Department Visits**  \n",
            "5. **Hospitalizations**  \n",
            "6. **Mortality** (COVID-19–associated deaths)  \n",
            "7. **Observational Study**  \n",
            "8. **Electronic Health Records**  \n",
            "9. **Department of Veterans Affairs**  \n",
            "10. **Active-Comparator Design**  \n",
            "11. **Influenza Vaccine** (co-administration)  \n",
            "12. **Risk Ratio**  \n",
            "13. **Subgroup Analysis**  \n",
            "14. **Clinical Outcomes**  \n",
            "\n",
            "**Additional Relevant Terms:**  \n",
            "- **Inverse-Probability Weighting**  \n",
            "- **180-Day Follow-Up**  \n",
            "- **Veterans Cohort**  \n",
            "- **Public Health Vaccination Uptake**  \n",
            "\n",
            "These terms capture the study’s focus on vaccine performance, methodology, outcomes, and population. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **(2) Exemplar Similarity**"
      ],
      "metadata": {
        "id": "2cFvaj7o20aM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Similar exemplars (Good) ----------\n",
        "message = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"\"\"\n",
        "Read the following abstract and summarize its key PICO elements in this format:\n",
        "\n",
        "#Population : Short description\n",
        "#Intervention : Short description\n",
        "#Outcome : Short description\n",
        "\n",
        "<text>\n",
        "{ABSTRACT}\n",
        "</text>\n",
        "\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(messages=message)\n",
        "print(\"Good (similar) format:\\n\", response, \"\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3N-l0xeq5fNT",
        "outputId": "57c43591-7ede-44f8-83eb-65f53346f529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good (similar) format:\n",
            " #Population : U.S. veterans aged ≥18 years who received either the 2024–2025 Covid-19 vaccine alone or in combination with the influenza vaccine (164,132 participants) and those who received only the influenza vaccine (131,839 participants) between September 3 and December 31, 2024.  \n",
            "\n",
            "#Intervention : Receipt of the 2024–2025 Covid-19 vaccine (administered either alone or simultaneously with the influenza vaccine).  \n",
            "\n",
            "#Outcome : Reduction in Covid-19–associated severe clinical outcomes at 6 months, including emergency department visits (29.3% effectiveness), hospitalizations (39.2% effectiveness), and deaths (64.0% effectiveness), as well as a composite of these outcomes (28.3% effectiveness). \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Dissimilar exemplars (Bad) ----------\n",
        "message = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"\"\"\n",
        "Read the following abstract and summarize its key PICO elements using this format:\n",
        "\n",
        "Population short phrase - #Population# -\n",
        "#Intervention : Short description\n",
        "#Outcome : Short description\n",
        "\n",
        "<text>\n",
        "{ABSTRACT}\n",
        "</text>\n",
        "\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(messages=message)\n",
        "print(\"Bad (dissimilar) format:\\n\", response, \"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMAM8cn75h1f",
        "outputId": "390215f2-75df-4436-a76b-6bc3e8951f4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bad (dissimilar) format:\n",
            " #Population# - U.S. veterans receiving Covid-19 and/or influenza vaccines  \n",
            "#Intervention : 2024–2025 Covid-19 vaccine (co-administered with influenza vaccine)  \n",
            "#Outcome : Reduced risk of Covid-19–associated emergency department visits (29.3% VE), hospitalizations (39.2% VE), deaths (64.0% VE), and composite outcomes (28.3% VE) at 6 months  \n",
            "\n",
            "*(PICO breakdown: Population = veterans; Intervention = 2024–2025 Covid-19 vaccine; Comparison = influenza-only vaccine group; Outcomes = severe clinical outcomes as specified)* \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **(3) Exemplar Format**"
      ],
      "metadata": {
        "id": "gSV1g9u82wZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Good format (## Markdown headers) ----------\n",
        "message = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"\"\"\n",
        "Please extract the following entities from the abstract below.\n",
        "\n",
        "## Population\n",
        "## Intervention\n",
        "## Comparator\n",
        "## Outcomes\n",
        "## Study Design\n",
        "## Conclusion\n",
        "\n",
        "<abstract>\n",
        "{ABSTRACT}\n",
        "</abstract>\n",
        "\"\"\"\n",
        "    }\n",
        "]\n",
        "\n",
        "response = get_completion(messages=message)\n",
        "print(\"Good format (## headers):\\n\", response, \"\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q78CJFek05V9",
        "outputId": "cafbe2f0-b543-48a1-a4dd-2762d85e5cc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good format (## headers):\n",
            " Here are the extracted entities from the abstract:\n",
            "\n",
            "### **Population**  \n",
            "- **U.S. veterans** who received either:  \n",
            "  - Covid-19 and influenza vaccines on the same day (164,132 participants)  \n",
            "  - Influenza vaccine only (131,839 participants, active comparator group)  \n",
            "\n",
            "### **Intervention**  \n",
            "- **2024–2025 Covid-19 vaccine** administered between **September 3 and December 31, 2024**  \n",
            "\n",
            "### **Comparator**  \n",
            "- **Active comparator group**: Veterans who received **influenza vaccine only** (no Covid-19 vaccine) during the same period  \n",
            "\n",
            "### **Outcomes**  \n",
            "- **Covid-19–associated emergency department visits**  \n",
            "- **Covid-19–associated hospitalizations**  \n",
            "- **Covid-19–associated deaths**  \n",
            "- **Composite outcome** (any of the above three outcomes)  \n",
            "\n",
            "### **Study Design**  \n",
            "- **Observational study** using **electronic health records** from the **Department of Veterans Affairs**  \n",
            "- **Inverse-probability–weighted models** used to estimate vaccine effectiveness  \n",
            "- Follow-up period: **180 days** (or until outcome occurrence)  \n",
            "\n",
            "### **Conclusion**  \n",
            "- The **2024–2025 Covid-19 vaccine** was associated with **reduced risks** of severe clinical outcomes:  \n",
            "  - **29.3%** effectiveness against emergency department visits  \n",
            "  - **39.2%** effectiveness against hospitalizations  \n",
            "  - **64.0%** effectiveness against deaths  \n",
            "  - **28.3%** effectiveness against the composite outcome  \n",
            "- Benefits were observed **across prespecified subgroups**  \n",
            "\n",
            "Would you like any additional details or adjustments to the extracted entities? \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Bad format (ambiguous symbols: '-' and '%') ----------\n",
        "message = [\n",
        "    {\n",
        "        \"role\": \"user\",\n",
        "        \"content\": f\"\"\"\n",
        "Please extract the following entities from the abstract below.\n",
        "\n",
        "%Population\n",
        "%Intervention\n",
        "Comparator\n",
        "Outcomes%\n",
        "% Study Design\n",
        "%% Conclusion %\n",
        "\n",
        "%%%% ABSTRACT %%%%\n",
        "{ABSTRACT}\n",
        "\"\"\"\n",
        "    }\n",
        "]\n",
        "for i in range(2):\n",
        "    response = get_completion(messages=message)\n",
        "    print(f\"Bad format n={i} (symbols):\\n\", response, \"\\n\\n\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KAgMhJj8_zR",
        "outputId": "9bf908aa-3af9-48c2-f581-5d3c300b5f0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bad format n=0 (symbols):\n",
            " Here are the extracted entities from the abstract:  \n",
            "\n",
            "### **%Population**  \n",
            "- U.S. veterans who received either:  \n",
            "  - Covid-19 and influenza vaccines on the same day (164,132 participants)  \n",
            "  - Influenza vaccine only (131,839 participants, active comparator group)  \n",
            "\n",
            "### **%Intervention**  \n",
            "- **2024–2025 Covid-19 vaccine** (administered between September 3 and December 31, 2024)  \n",
            "\n",
            "### **Comparator**  \n",
            "- Veterans who received **influenza vaccine only** (active comparator group)  \n",
            "\n",
            "### **Outcomes%**  \n",
            "- **Covid-19–associated emergency department visits**  \n",
            "- **Covid-19–associated hospitalizations**  \n",
            "- **Covid-19–associated deaths**  \n",
            "- **Composite outcome** (any of the above three)  \n",
            "\n",
            "### **% Study Design**  \n",
            "- **Observational study** using **electronic health records** from the **Department of Veterans Affairs**  \n",
            "- **Inverse-probability–weighted models** used to estimate vaccine effectiveness  \n",
            "- Follow-up period: **180 days or until outcome occurrence**  \n",
            "\n",
            "### **%% Conclusion %%**  \n",
            "- The **2024–2025 Covid-19 vaccine** was associated with **reduced risks of severe clinical outcomes**, including:  \n",
            "  - **29.3% effectiveness** (95% CI, 19.1–39.2) against emergency department visits  \n",
            "  - **39.2% effectiveness** (95% CI, 21.6–54.5) against hospitalizations  \n",
            "  - **64.0% effectiveness** (95% CI, 23.0–85.8) against deaths  \n",
            "  - **28.3% effectiveness** (95% CI, 18.2–38.2) against the composite outcome  \n",
            "\n",
            "Would you like any additional details or adjustments? \n",
            "\n",
            "\n",
            "\n",
            "Bad format n=1 (symbols):\n",
            " Here are the extracted entities from the abstract:  \n",
            "\n",
            "### **Population**  \n",
            "- U.S. veterans who received Covid-19 and influenza vaccines on the same day (164,132 participants) or influenza vaccine only (131,839 participants).  \n",
            "\n",
            "### **Intervention**  \n",
            "- Receipt of the **2024–2025 Covid-19 vaccine** (administered concurrently with influenza vaccine).  \n",
            "\n",
            "### **Comparator**  \n",
            "- Veterans who received **influenza vaccine only** (active comparator group).  \n",
            "\n",
            "### **Outcomes**  \n",
            "1. Covid-19–associated **emergency department visits**  \n",
            "2. Covid-19–associated **hospitalizations**  \n",
            "3. Covid-19–associated **deaths**  \n",
            "4. Composite outcome (emergency department visits, hospitalizations, or deaths)  \n",
            "\n",
            "### **Study Design**  \n",
            "- **Observational cohort study** using electronic health records from the Department of Veterans Affairs.  \n",
            "- Follow-up period: **180 days** (or until outcome occurrence).  \n",
            "- Analytical method: **Inverse-probability–weighted models** to estimate vaccine effectiveness (1 − risk ratio).  \n",
            "\n",
            "### **Conclusion**  \n",
            "- The **2024–2025 Covid-19 vaccine** was associated with **reduced risks of severe clinical outcomes**, including:  \n",
            "  - **29.3%** effectiveness against emergency department visits,  \n",
            "  - **39.2%** effectiveness against hospitalizations,  \n",
            "  - **64.0%** effectiveness against deaths,  \n",
            "  - **28.3%** effectiveness against the composite outcome.  \n",
            "- Benefits were observed across prespecified subgroups.  \n",
            "\n",
            "Would you like any refinements or additional details? \n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IILw-VsToVwL"
      },
      "source": [
        "**References**\n",
        "\n",
        "[Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., ... & Amodei, D. (2020). *Language models are few-shot learners.* Advances in Neural Information Processing Systems, 33, 1877-1901.](https://arxiv.org/abs/2005.14165)\n",
        "\n",
        "[Wei, J., Bosma, M., Zhao, V. Y., Guu, K., Yu, A. W., Lester, B., ... & Le, Q. V. (2021). *Finetuned language models are zero-shot learners.* arXiv preprint arXiv:2109.01652.](https://arxiv.org/abs/2109.01652)\n",
        "\n",
        "[Work, W. M. I. C. L. *Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?*](https://arxiv.org/abs/2202.12837)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CiXpSpdKoVwL"
      },
      "source": [
        "*Next: [Chapter 5. Role and Style Prompting](./05_Chapter%205.%20Role%20and%20Style%20Prompting.ipynb)*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}